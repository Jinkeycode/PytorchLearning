# PytorchLearning

## 第一课 线性回归

原版 [/Lesson1_LinearRegression/LinearRegression_Original.ipynb](https://github.com/Jinkeycode/PytorchLearning/blob/master/Lesson1_LinearRegression/LinearRegression_Original.ipynb)

作业 [/Lesson1_LinearRegression/LinearRegression_Edited&Homework.ipynb](https://github.com/Jinkeycode/PytorchLearning/blob/master/Lesson1_LinearRegression/LinearRegression_Edited%26Homework.ipynb)

## 第二课 Softmax与分类模型
原版 [/Lesson2_Softmax/Softmax_Original.ipynb](https://github.com/Jinkeycode/PytorchLearning/blob/master/Lesson2_Softmax/Softmax_Original.ipynb)

作业 [/Lesson2_Softmax/Softmax_Edited&Homework.ipynb](https://github.com/Jinkeycode/PytorchLearning/blob/master/Lesson2_Softmax/Softmax_Edited%26Homework.ipynb)

## 第三课 多层感知机
原版 [/Lesson3_MultilayerPerceptron/MultilayerPerceptron_Original.ipynb](https://github.com/Jinkeycode/PytorchLearning/blob/master/Lesson2_Softmax/Softmax_Original.ipynb)

作业 [/Lesson3_MultilayerPerceptron/MultilayerPerceptron_Edited&Homework.ipynb](https://github.com/Jinkeycode/PytorchLearning/blob/master/Lesson2_Softmax/Softmax_Edited%26Homework.ipynb)

## 第四课 过拟合、欠拟合及其解决方案
待补充

## 第五课 梯度消失、梯度爆炸
待补充

## 第六课 卷积神经网络基础
待补充

## 第七课 LeNet
待补充

## 第八课 卷积神经网络进阶
待补充

## 第九课 批量归一化和残差网络
待补充

## 第十课 文本预处理
待补充

## 第十二课 语言模型
待补充 

## 第十三课 循环神经网络基础
待补充

## 第十四课 循环神经网络进阶
待补充

## 第十五课 机器翻译及相关技术
待补充

## 第十六课 注意力机制与Seq2seq模型
待补充

## 第十七课 Transformer
待补充

## 第十八课 凸优化
待补充

## 第十九课 梯度下降
待补充

## 第二十课 优化算法进阶
待补充
